# -*- coding: utf-8 -*-
"""HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fjweyaAu9YPRogZUEU-ufcNqv7Ygs8Gr

# DL Homework 1
## It is at https://colab.research.google.com/drive/1fjweyaAu9YPRogZUEU-ufcNqv7Ygs8Gr
---


*   Bingqing Wei(bw2581)
*   Yue Luo(yl4003)

# Part 1. Implement own NN and run on Cifar10.

# Data Preparation and Visualization
"""

import torch, torchvision
import numpy as np

# Define Get Function for Cifar10 Dataset
def get_c10():
    transform = torchvision.transforms.Compose(
        [torchvision.transforms.ToTensor(),
         torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
    )

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform)
    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform)
    return trainset, testset
    

# Split trainset and get dataloaders
def get_loader(trainset, testset, valid_size=0.1, n=32): #n is batch_size
    num_train = len(trainset)
    indices = list(range(num_train))
    split = int(np.floor(valid_size * num_train))

    np.random.seed(1)
    np.random.shuffle(indices)

    train_idx, valid_idx = indices[split:], indices[:split]
    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)
    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)

    train_loader = torch.utils.data.DataLoader(
        trainset, batch_size=n, sampler=train_sampler)

    valid_loader = torch.utils.data.DataLoader(
        trainset, batch_size=1000, sampler=valid_sampler)

    test_loader = torch.utils.data.DataLoader(
        testset, batch_size=1000, shuffle=False)
    return train_loader, valid_loader, test_loader
  
# Data Preprocessing for Cifar10 dataset
def data_preprocess_cifar10(images, labels):
    batch_size = images.shape[0]
    images = images.numpy()
    images_ = np.reshape(images, (batch_size,np.prod(images.shape[1:])))

    labels_ = np.zeros((batch_size,10)) # batch_size * 10
    for i in range(batch_size):
      labels_[i, labels[i]] = 1
    return images_, labels_

# Download dataset
trainset, testset = get_c10()

# Get a understanding on the dataset
print("Train Set Info:")
print(trainset)
print("\nTest Set Info:")
print(testset)

## Do some Visualization on dataset.
import matplotlib.pyplot as plt
def imshow(img):
  img = img / 2 + 0.5 # unnormalize
  npimg = img.numpy()
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  
labels = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]
idx1 = 5
imshow(trainset[idx1][0]) # displays train image number 5
print("Train Label: " + str(trainset[idx1][1]) +"("+labels[trainset[idx1][1]]+")")

idx2 = 2
imshow(testset[idx2][0]) # displays test image number 2
print("Test Label: " + str(testset[idx2][1]) +"("+labels[testset[idx2][1]]+")")

"""# NN Model Class Detail."""

# Implementation of the layers. 
# We don't exactly follow the template, but seperate the layers and NN into different class.
from collections import Counter
import numpy as np

np.random.seed(2019)

def init_weight(shape):
    norm = np.sqrt(2.0 / (np.sum(shape)))
    return np.random.randn(shape[0], shape[1]) * norm

class Layer:
    def __init__(self, prev, input_shape):
        assert len(input_shape) == 2
        self.prev = prev
        self.input_shape = input_shape
        self.grads = {} # key: parameter, value: (batch_size, parameter shape)
        self.mode = 'train'

    def backward(self, dy):
        raise NotImplementedError()

    def forward(self, x):
        raise NotImplementedError()

    def get_output_shape(self):
        raise NotImplementedError()

    def set_mode(self, mode='train'):
        self.mode = mode

class Input(Layer):
    def __init__(self, input_shape):
        super(Input, self).__init__(None, input_shape)

    def backward(self, dy):
        pass

    def forward(self, x):
        return x

    def get_output_shape(self):
        return self.input_shape
      
class FullyConnected(Layer):
    def __init__(self, prev, hidden_nb):
        assert isinstance(prev, Layer)
        input_shape = prev.get_output_shape()
        super(FullyConnected, self).__init__(prev, input_shape)
        self.W = init_weight((input_shape[-1], hidden_nb))
        self.bias = np.zeros(hidden_nb) + 0.01
        self.x = None

    def backward(self, dy):
        if self.x is None:
            raise ValueError('forward not called before backward')
        self.grads['W'] = np.matmul(np.transpose(self.x), dy) / dy.shape[0]
        self.grads['bias'] = np.average(dy, 0)
        return np.matmul(dy, np.transpose(self.W))

    def forward(self, x):
        self.x = x
        return np.matmul(x, self.W) + self.bias

    def get_output_shape(self):
        return self.input_shape[0], self.W.shape[-1]

class Relu(Layer):
    def __init__(self, prev):
        assert isinstance(prev, Layer)
        input_shape = prev.get_output_shape()
        super(Relu, self).__init__(prev, input_shape)
        self.x = None

    def backward(self, dy):
        # return dy ## TODO: Is this correct?
        if self.x is None:
            raise ValueError('forward not called before backward')
        return dy * (self.x > 0)

    def forward(self, x):
        self.x = x
        x[x < 0] = 0
        return x

    def get_output_shape(self):
        return self.input_shape

class CrossEntropyWithSoftmax(Layer):
    def __init__(self, prev):
        assert isinstance(prev, Layer)
        input_shape = prev.get_output_shape()
        super(CrossEntropyWithSoftmax, self).__init__(prev, input_shape)
        self.sft = None
        self.y = None

    def backward(self, dy):
        if self.sft is None or self.y is None:
            raise ValueError('forward not called before backward')
        return dy * (self.sft - self.y)

    def forward(self, x): # What is this doing?
        shift = x - np.expand_dims(np.max(x, axis=1), axis=1)
        exps = np.exp(shift)
        self.sft = np.apply_along_axis(lambda z: z / np.sum(z), 1, exps)
        return self.sft

    def loss(self, y):
        if self.sft is None:
            raise ValueError('forward not called before computing loss')
        self.y = y
        return -np.sum(y * np.log(self.sft))

    def get_output_shape(self):
        return self.input_shape[0], 1

# NN Class Definition.
class NeuralNetwork:
    def __init__(self, layers):
        self.layers = layers

    def forward(self, x, y):
        for i in range(len(self.layers)):
            x = self.layers[i].forward(x)
        loss = self.layers[-1].loss(y)
        return x, loss

    def backward(self):
        dy = 1.0
        for i in range(len(self.layers) - 1, -1, -1):
            dy = self.layers[i].backward(dy)

    def optimize(self, lr=0.01):
        self.backward()
        for layer in reversed(self.layers):
            for w in layer.grads.keys():
                update = lr * layer.grads[w]
                x = getattr(layer, w)
                x -= update

    def eval(self, result, y):
        x1 = np.argmax(result, axis=1)
        x2 = np.argmax(y, axis=1)
        corr = np.sum(x1 == x2)
        return corr

    def print(self, counter, epoch_nb, epoch_end=False, freq=1000, mode='train'):
        if epoch_end:
            print(mode.upper() + ': Epoch {} counts {}/ Accuracy:{:.3%}, Loss:{:.5f}'.format(epoch_nb, counter['count'],
                                                                              counter['cr']/counter['count'],
                                                                              counter['loss']/counter['count']))
            print('#' * 30)
        else:
            if counter['count'] % freq == 0:
              print('Epoch {} counts {}/ Accuracy:{:.3%}, Loss:{:.5f}'.format(epoch_nb, counter['count'],
                                                                counter['cr']/counter['count'],
                                                                counter['loss']/counter['count']))

    def set_mode(self, mode='train'):
        assert mode in ['train', 'test', 'valid']
        for l in self.layers:
            l.set_mode(mode)
            

    def train(self, train_loader, valid_loader, epoch=20, lr=0.01):
        def reset(counter):
            for k in counter:
                counter[k] = 0

        counter = Counter()
        counter['cr'] = 0
        counter['loss'] = 0
        counter['count'] = 0
        iter_step = 10
        print("Start Training...")
        for e in range(epoch):
            self.set_mode('train')
            reset(counter)
            for x, y in train_loader:
                x, y = data_preprocess_cifar10(x, y)
                batch_size = y.shape[0]
                r, loss = self.forward(x, y)
                self.optimize(lr)
                cr = self.eval(r, y)
                counter['count'] += y.shape[0]
                counter['cr'] += cr
                counter['loss'] += loss
                self.print(counter, epoch_nb=e, epoch_end=False, freq=batch_size*iter_step, mode='train')
            self.print(counter, epoch_nb=e, epoch_end=True, mode='train')
            
            reset(counter)
            self.set_mode('valid')
            for x, y in valid_loader:
                x, y = data_preprocess_cifar10(x, y)
                r, loss = self.forward(x, y)
                cr = self.eval(r, y)
                counter['count'] += y.shape[0]
                counter['cr'] += cr
                counter['loss'] += loss
            self.print(counter, epoch_nb=e, epoch_end=True, mode='valid')

    def test(self, test_loader):
        counter = Counter()
        counter['cr'] = 0
        counter['loss'] = 0
        counter['count'] = 0
        print("Start Testing...")
        self.set_mode('test')
        for x, y in test_loader:
            x, y = data_preprocess_cifar10(x, y)
            r, loss = self.forward(x, y)
            cr = self.eval(r, y)
            counter['count'] += y.shape[0]
            counter['cr'] += cr
            counter['loss'] += loss
        self.print(counter, epoch_nb=0, epoch_end=True, mode='test')

"""# NN Model Training on Cifar10"""

# Model Setting.
def model_config(batch_size=32):
    input_layer = Input((batch_size, 3072))
    d1_layer = FullyConnected(input_layer, 2048)
    a1_layer = Relu(d1_layer)

    d2_layer = FullyConnected(a1_layer, 2048)
    a2_layer = Relu(d2_layer)

    d3_layer = FullyConnected(a2_layer, 1024)
    a3_layer = Relu(d3_layer)

    d4_layer = FullyConnected(a3_layer, 512)
    a4_layer = Relu(d4_layer)

    d9_layer = FullyConnected(a4_layer, 10)

    a9_layer = CrossEntropyWithSoftmax(d9_layer)
    model = NeuralNetwork([input_layer, d1_layer, a1_layer, d2_layer, a2_layer, d3_layer, a3_layer, d4_layer, a4_layer, d9_layer, a9_layer])
    return model

## Get dataloader and select model.
batch_size = 128
train_loader, valid_loader, test_loader = get_loader(trainset, testset, n=batch_size)
model = model_config(batch_size=batch_size)

## Start training
model.train(train_loader, valid_loader, epoch=20, lr=0.01)

"""We manually stop after Epoch 12. 

We see that the training accuary is around 68.9%(At begining it is 11%). Training loss decreases from 2.3 to now 0.9.

For validation set, accuracy reach 50% and stay around 51% in the last few epoches. Loss is around 1.4.

The training may start to overfit the training set. We need some regularization method to further increase preformance in validation set.(But we are not doing it here)

# NN Model Testing on Cifar10
"""

import matplotlib.pyplot as plt

## Testing
model.test(test_loader)

# visualization
def imshow(img):
    img = img / 2 + 0.5 # unnormalize
    plt.imshow(np.transpose(img, (1, 2, 0)))

def test_visual(model, test_loader):
    print("Visualization on some test images....")
    columns = 4
    rows = 4
    sample = columns * rows
    fig = plt.figure(figsize=(16,22))
    for x, y in test_loader:
        x, y = data_preprocess_cifar10(x, y)
        x = x[:sample, :]
        y = y[:sample, :]
        r, loss = model.forward(x, y)
        r = np.argmax(r, axis=1)
        y = np.argmax(y, axis=1)
        break

    labels = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]
    ax = []
    for i in range(sample):
      s1 = "Pred: " + str(r[i]) +" ("+labels[r[i]]+")"
      s2 = "Actual: " + str(y[i]) +" ("+labels[y[i]]+")"
      if r[i] == y[i] :
        correct = "Correct!"
      else:
        correct = "Wrong!!"
      s = s1 + " / " + s2 + "\n " + correct
      ax.append( fig.add_subplot(rows, columns, i+1) )
      ax[-1].set_title(s)  # set title
      imshow(np.reshape(x[i,:],(3,32,32)))
    plt.show()
    print("{}/{} correct...".format(np.sum(r==y),r.size))
    
test_visual(model, test_loader)

"""The Model runs for a 52% accuracy on the Cifar10 testset. And for some sample images, we can see some good performance for that model (12/16 correct).

# Part 2. CNN Using Pytorch
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

trainset, testset = get_c10()
batch_size = 128
train_loader, valid_loader, test_loader = get_loader(trainset, testset, n=batch_size)

"""# Model Trial 1. Baseline Model(2*Conv->Norm->Relu->MaxPool + 2fc + softmax) and SGD."""

# Flatten exact for the first batch channel
def num_flat_features(x):
    size = x.size()[1:]
    num_features = 1
    for s in size:
        num_features *= s
    return num_features
  
# Mnist Model
class MnistModel(nn.Module):
    def __init__(self):
        super(MnistModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 5, padding=2) 
        self.conv1_bn = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)
        self.conv2_bn = nn.BatchNorm2d(64)
        self.fc1 = nn.Linear(64*8*8, 1024)
        self.fc2 = nn.Linear(1024, 10)
        
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1_bn(self.conv1(x))), 2) # Conv->Normalization->Relu->MaxPool
        x = F.max_pool2d(F.relu(self.conv2_bn(self.conv2(x))), 2)
        x = x.view(-1, num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x)

# Select Model and optimization. Simple SGD
model_2_1 = MnistModel()
optimizer = optim.SGD(model_2_1.parameters(), lr=0.01)
# send model to GPU
model_2_1.cuda()

train_loss, train_accu = [], []
for epoch in range(20):
    count = 0
    hit = 0
    model_2_1.train() # to set train mode for drop out
    print("Start Training...")
    for images, labels in train_loader:
        # send tensors to GPU
        images, labels = images.cuda(), labels.cuda()
        count += images.shape[0]
        
        optimizer.zero_grad()               # zero the parameter gradients
        outputs = model_2_1(images)             # calls the forward function of model, i.e. model.forward(images)
        loss = F.nll_loss(outputs, labels)  # calculate loss
        loss.backward()                     # calculate gradients
        train_loss.append(loss.item())
        optimizer.step()                    # update learnable parameters
        predictions = outputs.data.max(1)[1]# column at idx 1 has actual prob.  
        
        # send tensors back to CPU because numpy ops don't support GPU.
        hit = np.sum(predictions.cpu().numpy()==labels.cpu().numpy())
        accuracy = hit/images.shape[0]
        train_accu.append(accuracy)
        if count % (batch_size*10) == 0 or count == batch_size:
            print('Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('TRAIN: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('#' * 30)
    
    model_2_1.eval()
    hit = 0
    count = 0
    for images, labels in valid_loader:
        with torch.no_grad(): # so that computation graph history is not stored
            images, labels = images.cuda(), labels.cuda() # send tensors to GPU
            count += images.shape[0]
            outputs = model_2_1(images)
            predictions = outputs.data.max(1)[1]
            hit += predictions.eq(labels.data).sum().cpu().numpy()
    accuracy = hit/count
    loss = F.nll_loss(outputs, labels)
    print('VALID: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('#' * 30)

## Testing
model_2_1.eval()
hit = 0
count = 0
for images, labels in test_loader:
    with torch.no_grad(): # so that computation graph history is not stored
        images, labels = images.cuda(), labels.cuda() # send tensors to GPU
        count += images.shape[0]
        outputs = model_2_1(images)
        predictions = outputs.data.max(1)[1]
        hit += predictions.eq(labels.data).sum().cpu().numpy()
accuracy = hit/count
loss = F.nll_loss(outputs, labels)
print('TEST: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))

"""# Model Trial 2. Add Dropout."""

# Mnist Model, with Dropout layer after fc layer
class MnistModel_dropout(nn.Module):
    def __init__(self):
        super(MnistModel_dropout, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 5, padding=2) 
        self.conv1_bn = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)
        self.conv2_bn = nn.BatchNorm2d(64)
        self.fc1 = nn.Linear(64*8*8, 1024)
        self.fc2 = nn.Linear(1024, 10)
        
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1_bn(self.conv1(x))), 2)
        x = F.max_pool2d(F.relu(self.conv2_bn(self.conv2(x))), 2)
        x = x.view(-1, num_flat_features(x)) # reshape before sending to fc layer
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training) # default p=0.5
        x = self.fc2(x)
        return F.log_softmax(x)

# Select Model and optimization. Simple SGD, dropout model.
model_2_2 = MnistModel_dropout()
optimizer = optim.SGD(model_2_2.parameters(), lr=0.01)
# send model to GPU
model_2_2.cuda()

train_loss, train_accu = [], []
for epoch in range(20):
    count = 0
    hit = 0
    model_2_2.train() # to set train mode for drop out
    print("Start Training...")
    for images, labels in train_loader:
        # send tensors to GPU
        images, labels = images.cuda(), labels.cuda()
        count += images.shape[0]
        
        optimizer.zero_grad()               # zero the parameter gradients
        outputs = model_2_2(images)             # calls the forward function of model, i.e. model.forward(images)
        loss = F.nll_loss(outputs, labels)  # calculate loss
        loss.backward()                     # calculate gradients
        train_loss.append(loss.item())
        optimizer.step()                    # update learnable parameters
        predictions = outputs.data.max(1)[1]# column at idx 1 has actual prob.  
        
        # send tensors back to CPU because numpy ops don't support GPU.
        hit = np.sum(predictions.cpu().numpy()==labels.cpu().numpy())
        accuracy = hit/images.shape[0]
        train_accu.append(accuracy)
        if count % (batch_size*10) == 0 or count == batch_size:
            print('Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('TRAIN: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('#' * 30)
    
    model_2_2.eval()
    hit = 0
    count = 0
    for images, labels in valid_loader:
        with torch.no_grad(): # so that computation graph history is not stored
            images, labels = images.cuda(), labels.cuda() # send tensors to GPU
            count += images.shape[0]
            outputs = model_2_2(images)
            predictions = outputs.data.max(1)[1]
            hit += predictions.eq(labels.data).sum().cpu().numpy()
    accuracy = hit/count
    loss = F.nll_loss(outputs, labels)
    print('VALID: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('#' * 30)

## Testing
model_2_2.eval()
hit = 0
count = 0
for images, labels in test_loader:
    with torch.no_grad(): # so that computation graph history is not stored
        images, labels = images.cuda(), labels.cuda() # send tensors to GPU
        count += images.shape[0]
        outputs = model_2_2(images)
        predictions = outputs.data.max(1)[1]
        hit += predictions.eq(labels.data).sum().cpu().numpy()
accuracy = hit/count
loss = F.nll_loss(outputs, labels)
print('TEST: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))

"""# Model Trail 3. Using SGD with Momentum."""

# Select Model and optimization. SGD with Momentum, baseline model
model_2_3 = MnistModel()
optimizer = optim.SGD(model_2_3.parameters(), lr=0.01, momentum=0.9)
# send model to GPU
model_2_3.cuda()

train_loss, train_accu = [], []
for epoch in range(20):
    count = 0
    hit = 0
    model_2_3.train() # to set train mode for drop out
    print("Start Training...")
    for images, labels in train_loader:
        # send tensors to GPU
        images, labels = images.cuda(), labels.cuda()
        count += images.shape[0]
        
        optimizer.zero_grad()               # zero the parameter gradients
        outputs = model_2_3(images)             # calls the forward function of model, i.e. model.forward(images)
        loss = F.nll_loss(outputs, labels)  # calculate loss
        loss.backward()                     # calculate gradients
        train_loss.append(loss.item())
        optimizer.step()                    # update learnable parameters
        predictions = outputs.data.max(1)[1]# column at idx 1 has actual prob.  
        
        # send tensors back to CPU because numpy ops don't support GPU.
        hit = np.sum(predictions.cpu().numpy()==labels.cpu().numpy())
        accuracy = hit/images.shape[0]
        train_accu.append(accuracy)
        if count % (batch_size*10) == 0 or count == batch_size:
            print('Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('TRAIN: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('#' * 30)
    
    model_2_3.eval()
    hit = 0
    count = 0
    for images, labels in valid_loader:
        with torch.no_grad(): # so that computation graph history is not stored
            images, labels = images.cuda(), labels.cuda() # send tensors to GPU
            count += images.shape[0]
            outputs = model_2_3(images)
            predictions = outputs.data.max(1)[1]
            hit += predictions.eq(labels.data).sum().cpu().numpy()
    accuracy = hit/count
    loss = F.nll_loss(outputs, labels)
    print('VALID: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))
    print('#' * 30)

## Testing
model_2_3.eval()
hit = 0
count = 0
for images, labels in test_loader:
    with torch.no_grad(): # so that computation graph history is not stored
        images, labels = images.cuda(), labels.cuda() # send tensors to GPU
        count += images.shape[0]
        outputs = model_2_3(images)
        predictions = outputs.data.max(1)[1]
        hit += predictions.eq(labels.data).sum().cpu().numpy()
accuracy = hit/count
loss = F.nll_loss(outputs, labels)
print('TEST: Epoch {}\tCount {}/\tAccuracy {:.3%}\tLoss {:.5f}'.format(epoch, count, accuracy, loss.item()))

"""# Comparsion and Result

In total we run 3 trials. 

First one is the baseline model(Baseline Model(2*Conv->Norm->Relu->MaxPool + 2fc + softmax)), and use SGD with lr=0.01. After 20 epoch, training accuracy is stably around **80-82%**, training loss is reduced to around **0.6** from begining **2.27**. Validation accuracy is about** 71.4%**. Accuracy on test set is  **71.43%**.

In the second trial, we add one **dropout layer** after the first fc layer, in order to increase the capacity of the model. It still runs with SGD with lr=0.01. After 20 epoch, training accuracy is around **77%**, loss is about **0.67**. But it gets better generalization ability, getting **73.86%** accuracy on validation set and **72.77%** on test set, meaning a roughly **1-2%** boost due to dropout layer.

In the last trial, we do not use dropout layer, but instead change the optimizer to be SGD with momentum(0.9), lr=0.01. It shows a significant improment. Training converges much faster. Validation accuracu gets over **70%** after 3-4 epochs. After 20 epochs, training accuracy is now **100%**, with loss to only **0.002**. Validation accuracy is now **79%** and test set has accuracy **78.5%**, both have a increase of **7-8%** compared to baseline model.
"""